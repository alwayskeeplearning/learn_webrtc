# WebRTC 学习笔记: 部分1 - 核心理论与准备工作

本文档总结了 WebRTC 学习教程第一部分的核心知识点，包括 API 理论、关键概念，以及在学习过程中深入探讨的各类问题。

## 步骤 1.1: WebRTC 核心价值与概念

### 1. WebRTC 核心价值

- **无插件**: 无需安装任何浏览器插件（如 Flash），原生支持。
- **点对点 (P2P)**: 连接建立后，音视频和数据流在浏览器之间直接传输，延迟低，节省服务器带宽。
- **实时通信**: 为 Web 应用提供了原生的实时音视频和数据交换能力。

### 2. 主要应用场景

- 视频通话、在线教育、视频会议、直播互动、P2P 文件传输、云游戏等。

### 3. 与 WebSocket 的本质区别

- **WebSocket**: 客户端-服务器 (C/S) 模型。所有数据必须经过服务器中转。
- **WebRTC**: 主要是浏览器-浏览器 (P2P) 模型。数据在连接建立后直连。

### 4. 深入探讨：信令服务器 (Signaling)

- **问**: WebRTC 在局域网内可以完全不需要服务器吗？
- **答**: **不行**。WebRTC 通信分为两个阶段：
  1.  **连接建立阶段**: **必须**通过一个“信令服务器”来交换双方的网络信息 (SDP, ICE Candidates) 以完成“握手”。
  2.  **数据传输阶段**: 握手成功后，在局域网内数据流是**真正的 P2P**，不再经过服务器。
- **问**: 能不能手动把连接信息（如 IP、端口）通过二维码等方式发给对方，从而跳过信令服务器？
- **答**: **理论上可以，实践上不可行**。因为连接信息（特别是 ICE Candidates）是**动态发现**和**高频交换**的，手动复制粘贴无法跟上这个复杂、高速、双向的协商过程。
- **问**: 能不能让其中一个客户端 A 同时充当信令服务器？
- **答**: **完全可以**。这是一种“客户端即服务器”的架构。B 可以直接连接到 A 启动的 WebSocket 服务来进行信令交换。这种模型适用于特定场景（如局域网调试），但对于通用的互联网应用，独立的信令服务器在服务发现和扩展性上更有优势。

---

## 步骤 1.2: WebRTC 三大核心 API

1.  **`getUserMedia()`**:

    - **作用**: 获取用户**摄像头和麦克风**的权限。
    - **产出**: 返回一个 `MediaStream` 对象，它是媒体轨道 (Tracks) 的容器。
    - **`getDisplayMedia()`**: 一个功能类似的 API，专门用于获取**屏幕共享**的 `MediaStream`。

2.  **`RTCPeerConnection`**:

    - **作用**: WebRTC 的**核心引擎**。负责建立和管理 P2P 连接，处理所有复杂的网络协商（NAT 穿透、ICE、SDP）。

3.  **`RTCDataChannel`**:
    - **作用**: 在已建立的 P2P 连接上，提供一个**通用数据传输通道**，API 类似 WebSocket，可用于传输文本、JSON、文件等。

---

## 步骤 1.3: 初始化项目结构

- 我们在一个已有的 React + TypeScript + Less 的脚手架上进行了开发。
- **UI 结构**:
  - 创建了两个 `<video>` 元素，分别用于显示本地 (`localVideo`) 和远程 (`remoteVideo`) 的媒体流。
  - 为 `<video>` 元素设置了 `autoPlay`, `playsInline`, `muted` (本地视频静音防回声) 属性。
  - 创建了“开始分享”、“呼叫”、“挂断”三个按钮，并为后续逻辑准备了 `disabled` 状态。

---

## 步骤 1.4 & 1.5: 获取并播放本地媒体流

### 1. `MediaStream` 与 `MediaStreamTrack`

- **问**: 轨道 (Track) 是什么概念？
- **答**: **轨道是基本数据单元**，代表一个持续的媒体来源（如一个摄像头，或一个麦克风）。**流 (Stream) 是一个或多个轨道的集合/容器**。
- **问**: `new MediaStream([videoTrack, audioTrack])` 中轨道的顺序重要吗？
- **答**: **不重要**。系统通过 `track.kind` 属性 (`'video'` 或 `'audio'`) 来识别轨道类型，与顺序无关。

### 2. 媒体轨道的控制 (非常重要)

- **问**: 如何暂停/恢复视频分享？`track.start()` / `track.stop()`？
- **答**:
  - **`track.stop()`**: 是一个**不可逆的**终结操作，一旦调用，轨道即销毁，无法恢复。
  - **`track.enabled = false`**: **正确的“暂停”方法**。这会使轨道发送黑帧（视频）或静音（音频），但轨道本身是存活的，可以随时通过 `track.enabled = true` 恢复。
- **问**: 当 A 调用 `track.enabled = false` 后，B 如何知道 A 暂停了？
- **答**:
  - B **无法**通过 WebRTC 原生事件直接得知。
  - **最佳实践**是通过**信令通道**（如 WebSocket 或 DataChannel）发送一条自定义消息来同步媒体状态。
- **问**: `track.muted` 属性是做什么的？
- **答**:
  - 它是一个**只读**属性，是接收端用来判断媒体流是否**因外部原因（主要是网络中断）而中断**的**状态指示器**。
  - 当数据流中断时，`muted` 会变为 `true`，并触发 `mute` 事件。当数据流恢复时，`muted` 变为 `false`，并触发 `unmute` 事件。
  - 它与发送方主动设置的 `enabled` 状态无关。

### 3. 代码实现

- 使用 React 的 `useRef` 来获取对 `<video>` 元素的引用。
- 在 `useEffect` Hook (或按钮的 `onClick` 事件) 中调用 `navigator.mediaDevices.getDisplayMedia({ video: true })`。
- 成功获取 `stream` 对象后，通过 `localVideoRef.current.srcObject = stream;` 将其赋值给 video 元素的 `srcObject` 属性进行播放。
